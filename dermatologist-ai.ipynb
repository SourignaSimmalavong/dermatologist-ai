{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dermatologist AI\n",
    "\n",
    "This artificial neural networks classifies the following kinds of skin marks:\n",
    "* **melanoma**: this term will be used for _malignant melanoma_ (https://en.wikipedia.org/wiki/Melanoma)\n",
    "* **nevus**: it is a birthmark (https://en.wikipedia.org/wiki/Nevus)\n",
    "* **seborreic keratosis**: it is a benign skin tumour (https://en.wikipedia.org/wiki/Seborrheic_keratosis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images\n",
      "                      train\tvalid\ttest\n",
      "Melanoma:             374\t30\t117\n",
      "Nevus:                1372\t78\t393\n",
      "Seborrheic keratosis: 254\t42\t90\n",
      "-----------------------------------------------\n",
      "Total:                2000\t150\t600\n"
     ]
    }
   ],
   "source": [
    "classes_names = ['melanoma', 'nevus', 'seborrheic_keratosis']\n",
    "datasets_names = ['train', 'valid', 'test']\n",
    "\n",
    "melanoma_files_count = dict()\n",
    "nevus_files_count = dict()\n",
    "seborrheic_keratosis_files_count = dict()\n",
    "\n",
    "for dataset_name in datasets_names:\n",
    "    melanoma_files_count[dataset_name] = len(np.array(glob(f\"data/{dataset_name}/melanoma/*\")))\n",
    "    nevus_files_count[dataset_name] = len(np.array(glob(f\"data/{dataset_name}/nevus/*\")))\n",
    "    seborrheic_keratosis_files_count[dataset_name] = len(np.array(glob(f\"data/{dataset_name}/seborrheic_keratosis/*\")))\n",
    "    \n",
    "print('Number of images')\n",
    "print('                      train\\tvalid\\ttest')\n",
    "print('Melanoma:             {}\\t{}\\t{}'.format(melanoma_files_count['train'], melanoma_files_count['valid'], melanoma_files_count['test']))\n",
    "print('Nevus:                {}\\t{}\\t{}'.format(nevus_files_count['train'], nevus_files_count['valid'], nevus_files_count['test']))\n",
    "print('Seborrheic keratosis: {}\\t{}\\t{}'.format(seborrheic_keratosis_files_count['train'], seborrheic_keratosis_files_count['valid'], seborrheic_keratosis_files_count['test']))\n",
    "print('-----------------------------------------------')\n",
    "total_train = melanoma_files_count['train'] + nevus_files_count['train'] + seborrheic_keratosis_files_count['train']\n",
    "total_valid = melanoma_files_count['valid'] + nevus_files_count['valid'] + seborrheic_keratosis_files_count['valid']\n",
    "total_test = melanoma_files_count['test'] + nevus_files_count['test'] + seborrheic_keratosis_files_count['test']\n",
    "print('Total:                {}\\t{}\\t{}'.format(total_train, total_valid, total_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and transform the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "data = dict()\n",
    "\n",
    "data_transforms = \\\n",
    "{\n",
    "    'train': transforms.Compose([transforms.ToTensor()]),\n",
    "    'valid': transforms.Compose([transforms.ToTensor()]),\n",
    "    'test': transforms.Compose([transforms.ToTensor()]),\n",
    "}\n",
    "\n",
    "for dataset_name in datasets_names:\n",
    "    data[dataset_name] = \\\n",
    "        datasets.ImageFolder(f\"data/{dataset_name}\", \n",
    "                             transform=data_transforms[dataset_name])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the samplers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 2000 samples out of 2000 (100%)\n",
      "valid on 150 samples out of 150 (100%)\n",
      "test on 600 samples out of 600 (100%)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "# A subset of the train data to train faster on CPU to check \n",
    "# if it converges fast enough\n",
    "subset_size = \\\n",
    "{\n",
    "    'train': 1,\n",
    "    'valid': 1,\n",
    "    'test': 1\n",
    "}\n",
    "\n",
    "samplers = dict()\n",
    "\n",
    "for dataset_name in datasets_names:\n",
    "    samples_count = len(data[dataset_name])\n",
    "    indices = list(range(samples_count))\n",
    "    np.random.shuffle(indices)\n",
    "    split = int(np.floor(subset_size[dataset_name] * samples_count))\n",
    "    idx = indices[:split]\n",
    "    samplers[dataset_name] = SubsetRandomSampler(idx)\n",
    "    print(f\"{dataset_name} on {len(idx)} samples out of {samples_count} ({subset_size[dataset_name] * 100}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# The worker function needs to be in another python file to work with jupyter notebooks.\n",
    "# See this thread: https://stackoverflow.com/questions/48915440/pandas-multiprocessing-cant-get-attribute-function-on-main\n",
    "from worker import worker_init_fn\n",
    "\n",
    "num_workers = 6\n",
    "classes_count = 3\n",
    "batch_size = 32\n",
    "\n",
    "loaders = dict()\n",
    "for dataset_name in datasets_names:\n",
    "    loaders[dataset_name] = \\\n",
    "        torch.utils.data.DataLoader(data[dataset_name],\n",
    "                                    batch_size=batch_size, \n",
    "                                    num_workers=num_workers,\n",
    "                                    sampler=samplers[dataset_name],\n",
    "                                    worker_init_fn=worker_init_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
